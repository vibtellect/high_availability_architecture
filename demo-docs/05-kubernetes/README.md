# Kubernetes Auto-Scaling Demo mit k6 Load Testing

Eine vollstÃ¤ndige Demo-Umgebung, die automatische Kubernetes Pod-Skalierung von 1 bis 10 Instanzen unter realistischer k6 Last zeigt.

## ğŸ¯ Demo-Ãœbersicht

**Was Sie sehen werden:**
- ğŸš€ **Automatische Pod-Skalierung** von 1 â†’ 10 Instanzen
- âš¡ **k6 Load Testing** mit realistischen Lastprofilen
- ğŸ“Š **Real-time Monitoring** in Grafana Dashboard
- ğŸ”„ **HPA Behavior** mit schnellem Scale-Up und kontrolliertem Scale-Down
- ğŸ“ˆ **Performance Metrics** wÃ¤hrend des gesamten Skalierungsprozesses

## ğŸš€ Quick Start

### Lokales Kubernetes (minikube/kind)

```bash
# 1. Cluster starten und Demo deployen
./demo-docs/scripts/k8s-auto-scaling-demo.sh

# 2. Dashboard Ã¶ffnen
http://localhost:3000/d/kubernetes-auto-scaling-demo
```

### AWS EKS Deployment

```bash
# 1. EKS Cluster erstellen (falls noch nicht vorhanden)
eksctl create cluster --name ha-demo-cluster --region us-west-2 --nodegroup-name standard-workers --node-type t3.medium --nodes 3 --nodes-min 1 --nodes-max 10 --managed

# 2. Demo auf EKS deployen
kubectl apply -k demo-docs/05-kubernetes/k8s/environments/aws-eks/

# 3. Load Test starten
kubectl apply -f demo-docs/05-kubernetes/k8s/demo/k6-load-test-job.yaml

# 4. Skalierung Ã¼berwachen
kubectl get hpa -w
```

## ğŸ“‹ Voraussetzungen

### Lokale Entwicklung
- âœ… **kubectl** konfiguriert und Cluster erreichbar
- âœ… **minikube** oder **kind** fÃ¼r lokales Testing
- âœ… **Docker** fÃ¼r Container Building
- âœ… **k6** fÃ¼r lokale Load Tests (optional)

### AWS Deployment
- âœ… **AWS CLI** konfiguriert
- âœ… **eksctl** fÃ¼r EKS Cluster Management
- âœ… **kubectl** fÃ¼r Kubernetes Operationen
- âœ… **ECR Repository** fÃ¼r Container Images

## ğŸ—ï¸ Architektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Kubernetes Cluster                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ k6 Load     â”‚    â”‚ Product      â”‚    â”‚ HPA Controller â”‚  â”‚
â”‚  â”‚ Test Job    â”‚â”€â”€â”€â†’â”‚ Service      â”‚â†â”€â”€â”€â”‚ (1-10 replicas)â”‚  â”‚
â”‚  â”‚             â”‚    â”‚ (Demo)       â”‚    â”‚                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Prometheus  â”‚    â”‚ Grafana      â”‚    â”‚ kube-state-    â”‚  â”‚
â”‚  â”‚ (Metrics)   â”‚    â”‚ (Dashboard)  â”‚    â”‚ metrics        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¬ Demo-Flow

### Phase 1: Initial Setup (1 min)
- Deployment des Product Service mit 1 Replica
- HPA Konfiguration mit aggressiven Thresholds
- Baseline Metrics Collection

### Phase 2: Load Ramp-Up (3 min)
- k6 startet mit 10 VUs
- Steigerung auf 50 VUs â†’ CPU/Memory steigt
- HPA triggert erste Skalierung (1 â†’ 3 Pods)

### Phase 3: Peak Load (2 min)
- k6 erreicht 100 VUs
- Maximale CPU/Memory Auslastung
- HPA skaliert auf 8-10 Pods

### Phase 4: Scale-Down (3 min)
- k6 reduziert Last auf 50 VUs â†’ 0 VUs
- Kontrolliertes Downscaling
- RÃ¼ckkehr zu 1-2 Pods

## ğŸ“Š Monitoring & Dashboards

### Grafana Dashboards
- **Auto-Scaling Overview**: Real-time Pod-Scaling Visualisierung
- **k6 Load Test Metrics**: VUs, Response Times, Error Rates
- **Resource Utilization**: CPU/Memory pro Pod und Gesamt
- **HPA Events**: Scaling-Entscheidungen und Timings

### Key Metrics
```bash
# Pod Count Ã¼ber Zeit
kubectl get pods -l app=product-service,version=demo -w

# HPA Status live
kubectl get hpa product-service-demo-hpa -w

# CPU/Memory Utilization
kubectl top pods -l app=product-service,version=demo
```

## âš™ï¸ Konfiguration

### HPA Settings (Demo-optimiert)
```yaml
spec:
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 40  # Aggressive fÃ¼r Demo
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 50  # Aggressive fÃ¼r Demo
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 15   # Sehr schnell
      policies:
      - type: Percent
        value: 200  # Verdoppelung bei Scale-Up
        periodSeconds: 15
    scaleDown:
      stabilizationWindowSeconds: 180  # Langsamer fÃ¼r Demo-Sichtbarkeit
```

### k6 Load Profile
```javascript
scenarios: {
  auto_scaling_test: {
    executor: 'ramping-vus',
    stages: [
      { duration: '1m', target: 10 },   // Warm-up
      { duration: '3m', target: 50 },   // Trigger Scaling
      { duration: '2m', target: 100 },  // Peak Load
      { duration: '2m', target: 50 },   // Sustain
      { duration: '1m', target: 0 },    // Scale Down
    ],
  },
}
```

## ğŸ› ï¸ Troubleshooting

### HÃ¤ufige Probleme

**HPA skaliert nicht:**
```bash
# Metrics Server prÃ¼fen
kubectl get deployment metrics-server -n kube-system

# HPA Status detailliert
kubectl describe hpa product-service-demo-hpa

# Pod Resource Requests prÃ¼fen
kubectl describe pod <pod-name>
```

**k6 Job startet nicht:**
```bash
# Job Status prÃ¼fen
kubectl get jobs
kubectl describe job k6-auto-scaling-test

# k6 Logs anzeigen
kubectl logs job/k6-auto-scaling-test
```

**Service nicht erreichbar:**
```bash
# Service Endpoints prÃ¼fen
kubectl get endpoints product-service-demo

# Pod Health Status
kubectl get pods -l app=product-service,version=demo
```

### Performance Tuning

**FÃ¼r schnellere Demo:**
- CPU Target auf 30% reduzieren
- Stabilization Window auf 10s reduzieren
- Memory Limits auf 128Mi fÃ¼r einfacheres Triggering

**FÃ¼r realistischere Demo:**
- CPU Target auf 60-70% erhÃ¶hen
- Stabilization Window auf 60s erhÃ¶hen
- Mehr diverse Load Patterns in k6

## ğŸŒ AWS-Spezifische Anpassungen

### EKS Optimierungen
```yaml
# Node Selector fÃ¼r Instance Types
nodeSelector:
  node.kubernetes.io/instance-type: t3.medium

# EKS-spezifische Annotations
annotations:
  eks.amazonaws.com/fargate-profile: "default"
```

### ECR Integration
```bash
# Image Build und Push
docker build -t $ECR_REGISTRY/product-service:latest .
docker push $ECR_REGISTRY/product-service:latest

# Kustomization fÃ¼r ECR
kubectl apply -k demo-docs/05-kubernetes/k8s/environments/aws-eks/
```

## ğŸ“ˆ Demo-Ergebnisse

**Typische Skalierungs-Timeline:**
- 0:00 - Demo Start: 1 Pod
- 1:30 - Erste Skalierung: 1 â†’ 3 Pods
- 3:00 - Weitere Skalierung: 3 â†’ 6 Pods
- 4:30 - Peak erreicht: 6 â†’ 10 Pods
- 7:00 - Scale-Down beginnt: 10 â†’ 6 Pods
- 9:00 - Demo Ende: 6 â†’ 2 Pods

**Performance Metrics:**
- Response Time: P95 < 2000ms wÃ¤hrend Skalierung
- Error Rate: < 0.1% wÃ¤hrend gesamter Demo
- Scaling Zeit: 30-60s fÃ¼r vollstÃ¤ndige Pod-VerfÃ¼gbarkeit

## ğŸ”§ Erweiterte Features

### Multi-Metric HPA
```yaml
# Custom Metrics (beispielhaft)
- type: Pods
  pods:
    metric:
      name: http_requests_per_second
    target:
      type: AverageValue
      averageValue: "1k"
```

### Predictive Scaling
```yaml
# VPA fÃ¼r Memory Prediction
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: product-service-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: product-service-demo
  updatePolicy:
    updateMode: "Auto"
```

## ğŸ“š Weitere Ressourcen

- [Kubernetes HPA Documentation](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)
- [k6 Load Testing Guide](https://k6.io/docs/)
- [AWS EKS Best Practices](https://aws.github.io/aws-eks-best-practices/)
- [Prometheus Monitoring](https://prometheus.io/docs/kubernetes/kubernetes_sd/)

---

**ğŸ’¡ Tipp fÃ¼r Live-Demos:**
Starten Sie die Demo mit `kubectl get pods -w` in einem separaten Terminal, um das Scaling live zu zeigen. Die Grafana Dashboards bieten zusÃ¤tzliche visuelle EindrÃ¼cke fÃ¼r das Publikum. 