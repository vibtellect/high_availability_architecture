# ğŸ’¥ Basic Chaos Engineering Demo

*â±ï¸ Dauer: 5-10 Minuten | ğŸ¯ Zielgruppe: DevOps, SRE, Platform Engineers*

---

## ğŸ¯ **Demo-Ziel**

Zeigen wie das System auf **Service-AusfÃ¤lle reagiert** und sich **selbst heilt**. Perfect fÃ¼r **Resilience-Demonstrationen** gegenÃ¼ber Operations-Teams.

### **ğŸ”¥ Was demonstrieren wir?**
- âœ… **Service Failure Recovery** - Automatische Neu-Starts
- âœ… **Load Balancer Behavior** - Traffic-Umleitung  
- âœ… **Monitoring Response** - Alert-System in Action
- âœ… **Business Continuity** - E-Commerce funktioniert weiter

---

## ğŸš€ **Demo Script (5 Minuten)**

### **Schritt 1: Baseline etablieren (60 sec)**

```bash
# 1. System Status zeigen
./check-demo-health.sh

# 2. Live Traffic generieren
# Terminal 1: Continuous API Calls
while true; do 
    curl -s http://localhost:8080/api/v1/products >/dev/null
    echo "$(date): Product API called"
    sleep 2
done
```

**Demo-Aussage:** *"Hier sehen Sie das System im normalen Betrieb - alle Services antworten schnell und zuverlÃ¤ssig."*

---

### **Schritt 2: Chaos einfÃ¼hren (90 sec)**

```bash
# Service bewusst "tÃ¶ten"
docker kill $(docker ps -q -f name=product-service)

# Sofort Monitoring prÃ¼fen
echo "ğŸ” Checking system response..."
curl -w "Response Time: %{time_total}s\n" http://localhost/api/v1/products
```

**Demo-Aussage:** *"Jetzt simulieren wir einen kritischen Service-Ausfall - das kann in Production durch Hardware-Probleme, Memory-Leaks oder Deployment-Fehler passieren."*

---

### **Schritt 3: Recovery beobachten (90 sec)**

```bash
# Auto-Recovery verfolgen
echo "â±ï¸  Watching auto-recovery..."
for i in {1..30}; do
    STATUS=$(docker ps -q -f name=product-service | wc -l)
    if [ $STATUS -eq 1 ]; then
        echo "âœ… Service recovered after ${i}0 seconds!"
        break
    fi
    echo "â³ Recovery attempt $i..."
    sleep 10
done
```

**Demo-Aussage:** *"Docker Compose erkennt den Ausfall automatisch und startet einen neuen Container. Das ist Self-Healing in Aktion!"*

---

### **Schritt 4: System Verification (60 sec)**

```bash
# Final Health Check
./check-demo-health.sh

# Performance Test nach Recovery
curl -w "Recovery Response Time: %{time_total}s\n" http://localhost:8080/api/v1/products
```

**Demo-Aussage:** *"Das System ist vollstÃ¤ndig wiederhergestellt - und das alles ohne manuellen Eingriff!"*

---

## ğŸ¬ **Advanced Chaos Scenarios**

### **ğŸŒ Network Partition Simulation**
```bash
# Network delay hinzufÃ¼gen
./chaos/network-chaos.sh --latency 1000ms

# Impact messen
time curl http://localhost:8080/api/v1/products

# Recovery
./chaos/network-chaos.sh --reset
```

### **ğŸ’¾ Database Chaos**
```bash
# LocalStack "tÃ¶ten"
docker kill $(docker ps -q -f name=localstack)

# Services beobachten - sollten graceful degradation zeigen
curl http://localhost:8080/health
```

### **ğŸ”„ Circuit Breaker Demo**
```bash
# Circuit Breaker auslÃ¶sen
./chaos/circuit-breaker-demo.sh

# Fallback-Behavior demonstrieren
curl http://localhost:8080/api/v1/products
```

---

## ğŸ“Š **Monitoring wÃ¤hrend Chaos**

### **ğŸ¯ Was in Grafana beobachten:**
1. **Service Health Metrics** â†’ Services gehen von GrÃ¼n auf Rot
2. **Response Time Spike** â†’ Latenz steigt wÃ¤hrend Ausfall
3. **Request Success Rate** â†’ Error Rate steigt kurzzeitig
4. **Recovery Metrics** â†’ Alles normalisiert sich automatisch

### **ğŸ” Was in Jaeger tracken:**
1. **Failed Traces** â†’ Requests die durch Ausfall fehlschlagen
2. **Retry Patterns** â†’ Load Balancer versucht Backups
3. **Recovery Traces** â†’ Neue Container verarbeiten Requests

---

## ğŸ¤” **Typische Demo-Fragen & Antworten**

**Q: "Wie lange dauert die Recovery in Production?"**  
**A:** *"In Kubernetes mit Health Checks: 10-30 Sekunden. Mit unserem Setup hier: 30-60 Sekunden."*

**Q: "Was passiert mit laufenden Requests?"**  
**A:** *"Der Load Balancer erkennt den Ausfall und routet neue Requests zu gesunden Instanzen. Laufende Requests kÃ¶nnen verloren gehen, daher sollten Clients Retry-Logic haben."*

**Q: "Wie verhindert man Cascade Failures?"**  
**A:** *"Circuit Breaker Pattern, Timeouts, Bulkhead Pattern und Rate Limiting. Das sehen wir in der nÃ¤chsten Demo."*

**Q: "Funktioniert das auch bei Database-AusfÃ¤llen?"**  
**A:** *"Ja, mit Read-Replicas und Connection Pooling. Wollen Sie das live sehen?"*

---

## ğŸ¯ **Demo-Varianten nach Zielgruppe**

### **ğŸ‘¨â€ğŸ’¼ Management Demo (3 min):**
- Nur Service Kill + Auto-Recovery zeigen
- **Focus:** "System heilt sich selbst = weniger Nacht-EinsÃ¤tze"

### **ğŸ”§ Technical Deep Dive (10 min):**
- Alle Chaos-Szenarien durchgehen
- **Focus:** Monitoring, Metriken, Recovery-Patterns

### **â˜ï¸ Production Readiness (15 min):**
- Advanced Scenarios + AWS EKS Integration
- **Focus:** Production-grade Resilience Patterns

---

## ğŸ’¡ **Pro-Demo-Tipps**

### **ğŸ¬ Presentation Flow:**
1. **"So funktioniert es normal"** â†’ Baseline
2. **"Das passiert bei AusfÃ¤llen"** â†’ Chaos  
3. **"So heilt es sich selbst"** â†’ Recovery
4. **"ZurÃ¼ck zum normalen Betrieb"** â†’ Verification

### **ğŸ—£ï¸ Sprache fÃ¼r Impact:**
- âœ… **"Automatische Wiederherstellung"** statt "Container Restart"
- âœ… **"Self-Healing System"** statt "Docker Compose Restart Policy"  
- âœ… **"Zero Manual Intervention"** statt "LÃ¤uft von alleine"

### **â° Timing Tricks:**
- **Baseline** schnell abhandeln - alle kennen "normalen" Betrieb
- **Chaos** langsam erklÃ¤ren - das ist der spannende Teil
- **Recovery** live verfolgen - das ist der Wow-Moment

---

**ğŸ”¥ Ready fÃ¼r die nÃ¤chste Stufe?**  
â†’ [ğŸŒ Network Chaos Engineering](02-network-chaos.md) - Latenz, Packet Loss & Partitions 