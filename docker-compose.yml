version: '3.8'

services:
  # LocalStack für AWS Services (DynamoDB, SNS, SQS, etc.)
  localstack:
    container_name: localstack-main
    image: localstack/localstack:3.5.0
    ports:
      - "127.0.0.1:4566:4566"  # LocalStack main port
      - "127.0.0.1:8000:4566"  # DynamoDB port mapping für compatibility
      - "127.0.0.1:4510-4559:4510-4559"
    environment:
      - SERVICES=dynamodb,sns,sqs,s3,lambda,apigateway,iam,cloudwatch
      - DEBUG=${DEBUG:-0}
      - DATA_DIR=/var/lib/localstack
      - DOCKER_HOST=unix:///var/run/docker.sock
      - PERSISTENCE=1
      - EAGER_SERVICE_LOADING=1
      - LOCALSTACK_AUTH_TOKEN=${LOCALSTACK_AUTH_TOKEN}
    volumes:
      - "./localstack-data:/var/lib/localstack"
      - "/var/run/docker.sock:/var/run/docker.sock"
    networks:
      microservices-network:
        # Set the container IP address in the 10.0.2.0/24 subnet
        ipv4_address: 10.0.2.20
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4566/_localstack/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  # Product Service - Kotlin
  product-service:
    build:
      context: ./app/services/product_service
      dockerfile: Dockerfile
    container_name: product-service
    ports:
      - "8080:8080"
    environment:
      - SPRING_PROFILES_ACTIVE=docker
      - AWS_DYNAMODB_ENDPOINT=http://localstack:4566
      - AWS_SNS_ENDPOINT=http://localstack:4566
      - AWS_REGION=eu-central-1
      - AWS_ACCESS_KEY_ID=dummy
      - AWS_SECRET_ACCESS_KEY=dummy
      - LOGGING_LEVEL_ROOT=INFO
      - LOGGING_LEVEL_COM_PRODUCT=DEBUG
      - LOGGING_LEVEL_COM_PRODUCT_EVENT=DEBUG
      - LOGGING_LEVEL_COM_PRODUCT_SERVICE=DEBUG
      - EVENTS_PRODUCT_ENABLED=true
    depends_on:
      localstack:
        condition: service_healthy
    networks:
      - microservices-network
    dns:
      - 10.0.2.20
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # User Service - Java
  user-service:
    build:
      context: ./app/services/user_service
      dockerfile: Dockerfile
    container_name: user-service
    ports:
      - "8081:8081"
    environment:
      - SPRING_PROFILES_ACTIVE=docker
      - AWS_DYNAMODB_ENDPOINT=http://localstack:4566
      - AWS_SNS_ENDPOINT=http://localstack:4566
      - AWS_REGION=eu-central-1
      - AWS_ACCESS_KEY_ID=test
      - AWS_SECRET_ACCESS_KEY=test
      - JWT_SECRET=myVerySecretKeyForJWTTokenGenerationThatShouldBeAtLeast256BitsLong
      - JWT_EXPIRATION=86400000
      - LOGGING_LEVEL_ROOT=INFO
      - LOGGING_LEVEL_COM_USER=DEBUG
      - EVENTS_USER_ENABLED=true
    depends_on:
      localstack:
        condition: service_healthy
    networks:
      - microservices-network
    dns:
      - 10.0.2.20
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Checkout Service - Go
  checkout-service:
    build:
      context: ./app/services/checkout_service
      dockerfile: Dockerfile
    container_name: checkout-service
    ports:
      - "8082:8082"
    environment:
      - GIN_MODE=release
      - PORT=8082
      - AWS_REGION=eu-central-1
      - AWS_ACCESS_KEY_ID=test
      - AWS_SECRET_ACCESS_KEY=test
      - AWS_DYNAMODB_ENDPOINT=http://localstack:4566
      - AWS_ENDPOINT=http://localstack:4566
      - SNS_TOPIC_ARN=arn:aws:sns:eu-central-1:000000000000:checkout-events
      - EVENTS_ENABLED=true
      - PRODUCT_SERVICE_URL=http://product-service:8080
      - USER_SERVICE_URL=http://user-service:8081
    depends_on:
      localstack:
        condition: service_healthy
      product-service:
        condition: service_healthy
      user-service:
        condition: service_healthy
    networks:
      - microservices-network
    dns:
      - 10.0.2.20
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "-O", "/dev/null", "http://localhost:8082/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Analytics Service - Python
  analytics-service:
    build:
      context: ./app/services/analytics_service
      dockerfile: Dockerfile
    container_name: analytics-service
    ports:
      - "8083:8083"
    environment:
      - FLASK_ENV=production
      - PORT=8083
      - AWS_REGION=eu-central-1
      - AWS_ACCESS_KEY_ID=test
      - AWS_SECRET_ACCESS_KEY=test
      - AWS_DYNAMODB_ENDPOINT=http://localstack:4566
      - AWS_SNS_ENDPOINT=http://localstack:4566
      - AWS_SQS_ENDPOINT=http://localstack:4566
      - ANALYTICS_EVENTS_TABLE=analytics-events
      - ANALYTICS_METRICS_TABLE=analytics-metrics
      - ANALYTICS_AGGREGATIONS_TABLE=analytics-aggregations
      - ANALYTICS_TOPIC_ARN=arn:aws:sns:eu-central-1:000000000000:analytics-events
      - PRODUCT_EVENTS_QUEUE=product-events-queue
      - USER_EVENTS_QUEUE=user-events-queue
      - CHECKOUT_EVENTS_QUEUE=checkout-events-queue
      - REDIS_URL=redis://redis:6379
      - EVENTS_ENABLED=true
      - BATCH_SIZE=100
      - PROCESSING_INTERVAL=30
      - PRODUCT_SERVICE_URL=http://product-service:8080
      - USER_SERVICE_URL=http://user-service:8081
      - CHECKOUT_SERVICE_URL=http://checkout-service:8082
      - LOG_LEVEL=INFO
    depends_on:
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy
      product-service:
        condition: service_healthy
      user-service:
        condition: service_healthy
      checkout-service:
        condition: service_healthy
    networks:
      - microservices-network
    dns:
      - 10.0.2.20
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Analytics Celery Worker
  analytics-worker:
    build:
      context: ./app/services/analytics_service
      dockerfile: Dockerfile
    container_name: analytics-worker
    command: ["python", "celery_worker.py", "--concurrency", "4", "--queues", "high_priority,aggregations,notifications", "--log-level", "INFO"]
    environment:
      - FLASK_ENV=production
      - AWS_REGION=eu-central-1
      - AWS_ACCESS_KEY_ID=test
      - AWS_SECRET_ACCESS_KEY=test
      - AWS_DYNAMODB_ENDPOINT=http://localstack:4566
      - AWS_SNS_ENDPOINT=http://localstack:4566
      - AWS_SQS_ENDPOINT=http://localstack:4566
      - ANALYTICS_EVENTS_TABLE=analytics-events
      - ANALYTICS_METRICS_TABLE=analytics-metrics
      - ANALYTICS_AGGREGATIONS_TABLE=analytics-aggregations
      - ANALYTICS_TOPIC_ARN=arn:aws:sns:eu-central-1:000000000000:analytics-events
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - LOG_LEVEL=INFO
    depends_on:
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy
      analytics-service:
        condition: service_healthy
    networks:
      - microservices-network
    dns:
      - 10.0.2.20
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import redis; r=redis.Redis(host='redis', port=6379, db=0); r.ping()"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Analytics Celery Worker for Maintenance Tasks
  analytics-worker-maintenance:
    build:
      context: ./app/services/analytics_service
      dockerfile: Dockerfile
    container_name: analytics-worker-maintenance
    command: ["python", "celery_worker.py", "--concurrency", "2", "--queues", "maintenance", "--log-level", "INFO"]
    environment:
      - FLASK_ENV=production
      - AWS_REGION=eu-central-1
      - AWS_ACCESS_KEY_ID=test
      - AWS_SECRET_ACCESS_KEY=test
      - AWS_DYNAMODB_ENDPOINT=http://localstack:4566
      - AWS_SNS_ENDPOINT=http://localstack:4566
      - AWS_SQS_ENDPOINT=http://localstack:4566
      - ANALYTICS_EVENTS_TABLE=analytics-events
      - ANALYTICS_METRICS_TABLE=analytics-metrics
      - ANALYTICS_AGGREGATIONS_TABLE=analytics-aggregations
      - ANALYTICS_TOPIC_ARN=arn:aws:sns:eu-central-1:000000000000:analytics-events
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - LOG_LEVEL=INFO
    depends_on:
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy
      analytics-service:
        condition: service_healthy
    networks:
      - microservices-network
    dns:
      - 10.0.2.20
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import redis; r=redis.Redis(host='redis', port=6379, db=0); r.ping()"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Analytics Celery Beat Scheduler
  analytics-beat:
    build:
      context: ./app/services/analytics_service
      dockerfile: Dockerfile
    container_name: analytics-beat
    command: ["python", "celery_worker.py", "--beat", "--log-level", "INFO"]
    environment:
      - FLASK_ENV=production
      - AWS_REGION=eu-central-1
      - AWS_ACCESS_KEY_ID=test
      - AWS_SECRET_ACCESS_KEY=test
      - AWS_DYNAMODB_ENDPOINT=http://localstack:4566
      - AWS_SNS_ENDPOINT=http://localstack:4566
      - AWS_SQS_ENDPOINT=http://localstack:4566
      - ANALYTICS_EVENTS_TABLE=analytics-events
      - ANALYTICS_METRICS_TABLE=analytics-metrics
      - ANALYTICS_AGGREGATIONS_TABLE=analytics-aggregations
      - ANALYTICS_TOPIC_ARN=arn:aws:sns:eu-central-1:000000000000:analytics-events
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - LOG_LEVEL=INFO
    depends_on:
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy
      analytics-service:
        condition: service_healthy
    networks:
      - microservices-network
    dns:
      - 10.0.2.20
    restart: unless-stopped
    volumes:
      - celerybeat-data:/tmp
    healthcheck:
      test: ["CMD", "python", "-c", "import redis; r=redis.Redis(host='redis', port=6379, db=0); r.ping()"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis for Caching
  redis:
    image: redis:7-alpine
    container_name: redis-cache
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    networks:
      - microservices-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 5s
      retries: 3

  # NGINX Load Balancer / API Gateway
  nginx:
    image: nginx:alpine
    container_name: api-gateway
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./infrastructure/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./infrastructure/nginx/conf.d:/etc/nginx/conf.d:ro
    depends_on:
      - product-service
      - user-service
      - checkout-service
    networks:
      - microservices-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 5s
      retries: 3

  # Grafana for Monitoring
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin123}
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana-data:/var/lib/grafana
      - ./infrastructure/grafana/dashboards:/var/lib/grafana/dashboards
      - ./infrastructure/grafana/provisioning:/etc/grafana/provisioning
    networks:
      - microservices-network
    restart: unless-stopped

  # Prometheus for Metrics Collection
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - microservices-network
    restart: unless-stopped

  # Jaeger for Distributed Tracing
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: jaeger
    ports:
      - "16686:16686"
      - "14268:14268"
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    networks:
      - microservices-network
    restart: unless-stopped

networks:
  microservices-network:
    driver: bridge
    ipam:
      config:
        - subnet: 10.0.2.0/24

volumes:
  localstack-data:
  redis-data:
  grafana-data:
  prometheus-data:
  celerybeat-data: 