version: '3.8'

services:
  # LocalStack für AWS Services (DynamoDB, SNS, SQS, etc.)
  localstack:
    container_name: localstack-main
    image: localstack/localstack:3.5.0
    ports:
      - "127.0.0.1:4566:4566"  # LocalStack main port
      - "127.0.0.1:8000:4566"  # DynamoDB port mapping für compatibility
      - "127.0.0.1:4510-4559:4510-4559"
    environment:
      - SERVICES=dynamodb,sns,sqs,s3,lambda,apigateway,iam,cloudwatch
      - DEBUG=${DEBUG:-0}
      - DATA_DIR=/var/lib/localstack
      - DOCKER_HOST=unix:///var/run/docker.sock
      - PERSISTENCE=1
      - EAGER_SERVICE_LOADING=1
      - LOCALSTACK_AUTH_TOKEN=${LOCALSTACK_AUTH_TOKEN}
    volumes:
      - "./localstack-data:/var/lib/localstack"
      - "/var/run/docker.sock:/var/run/docker.sock"
    networks:
      microservices-network:
        # Set the container IP address in the 10.0.2.0/24 subnet
        ipv4_address: 10.0.2.20
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4566/_localstack/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  # Product Service - Kotlin
  product-service:
    build:
      context: ./app/services/product_service
      dockerfile: Dockerfile
    container_name: product-service
    ports:
      - "8080:8080"
    environment:
      - SPRING_PROFILES_ACTIVE=docker
      - AWS_DYNAMODB_ENDPOINT=http://localstack:4566
      - AWS_SNS_ENDPOINT=http://localstack:4566
      - AWS_REGION=eu-central-1
      - AWS_ACCESS_KEY_ID=dummy
      - AWS_SECRET_ACCESS_KEY=dummy
      - LOGGING_LEVEL_ROOT=INFO
      - LOGGING_LEVEL_COM_PRODUCT=DEBUG
      - LOGGING_LEVEL_COM_PRODUCT_EVENT=DEBUG
      - LOGGING_LEVEL_COM_PRODUCT_SERVICE=DEBUG
      - EVENTS_PRODUCT_ENABLED=true
    depends_on:
      localstack:
        condition: service_healthy
    networks:
      - microservices-network
    dns:
      - 10.0.2.20
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # User Service - Java
  user-service:
    build:
      context: ./app/services/user_service
      dockerfile: Dockerfile
    container_name: user-service
    ports:
      - "8081:8081"
    environment:
      - SPRING_PROFILES_ACTIVE=docker
      - AWS_DYNAMODB_ENDPOINT=http://localstack:4566
      - AWS_SNS_ENDPOINT=http://localstack:4566
      - AWS_REGION=eu-central-1
      - AWS_ACCESS_KEY_ID=test
      - AWS_SECRET_ACCESS_KEY=test
      - JWT_SECRET=myVerySecretKeyForJWTTokenGenerationThatShouldBeAtLeast256BitsLong
      - JWT_EXPIRATION=86400000
      - LOGGING_LEVEL_ROOT=INFO
      - LOGGING_LEVEL_COM_USER=DEBUG
      - EVENTS_USER_ENABLED=true
    depends_on:
      localstack:
        condition: service_healthy
    networks:
      - microservices-network
    dns:
      - 10.0.2.20
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Checkout Service - Go
  checkout-service:
    build:
      context: ./app/services/checkout_service
      dockerfile: Dockerfile
    container_name: checkout-service
    ports:
      - "8082:8082"
    environment:
      - GIN_MODE=release
      - PORT=8082
      - AWS_REGION=eu-central-1
      - AWS_ACCESS_KEY_ID=test
      - AWS_SECRET_ACCESS_KEY=test
      - AWS_DYNAMODB_ENDPOINT=http://localstack:4566
      - AWS_ENDPOINT=http://localstack:4566
      - SNS_TOPIC_ARN=arn:aws:sns:eu-central-1:000000000000:checkout-events
      - EVENTS_ENABLED=true
      - PRODUCT_SERVICE_URL=http://product-service:8080
      - USER_SERVICE_URL=http://user-service:8081
    depends_on:
      localstack:
        condition: service_healthy
      product-service:
        condition: service_healthy
      user-service:
        condition: service_healthy
    networks:
      - microservices-network
    dns:
      - 10.0.2.20
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "-O", "/dev/null", "http://localhost:8082/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Analytics Service - Python
  analytics-service:
    build:
      context: ./app/services/analytics_service
      dockerfile: Dockerfile
    container_name: analytics-service
    ports:
      - "8083:8083"
    environment:
      - FLASK_ENV=production
      - PORT=8083
      - AWS_REGION=eu-central-1
      - AWS_ACCESS_KEY_ID=test
      - AWS_SECRET_ACCESS_KEY=test
      - AWS_DYNAMODB_ENDPOINT=http://localstack:4566
      - AWS_SNS_ENDPOINT=http://localstack:4566
      - AWS_SQS_ENDPOINT=http://localstack:4566
      - ANALYTICS_EVENTS_TABLE=analytics-events
      - ANALYTICS_METRICS_TABLE=analytics-metrics
      - ANALYTICS_AGGREGATIONS_TABLE=analytics-aggregations
      - ANALYTICS_TOPIC_ARN=arn:aws:sns:eu-central-1:000000000000:analytics-events
      - PRODUCT_EVENTS_QUEUE=product-events-queue
      - USER_EVENTS_QUEUE=user-events-queue
      - CHECKOUT_EVENTS_QUEUE=checkout-events-queue
      - REDIS_URL=redis://redis:6379
      - EVENTS_ENABLED=true
      - BATCH_SIZE=100
      - PROCESSING_INTERVAL=30
      - PRODUCT_SERVICE_URL=http://product-service:8080
      - USER_SERVICE_URL=http://user-service:8081
      - CHECKOUT_SERVICE_URL=http://checkout-service:8082
      - LOG_LEVEL=INFO
    depends_on:
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy
      product-service:
        condition: service_healthy
      user-service:
        condition: service_healthy
      checkout-service:
        condition: service_healthy
    networks:
      - microservices-network
    dns:
      - 10.0.2.20
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Analytics Celery Worker
  analytics-worker:
    build:
      context: ./app/services/analytics_service
      dockerfile: Dockerfile
    container_name: analytics-worker
    command: ["python", "celery_worker.py", "--concurrency", "4", "--queues", "high_priority,aggregations,notifications", "--log-level", "INFO"]
    environment:
      - FLASK_ENV=production
      - AWS_REGION=eu-central-1
      - AWS_ACCESS_KEY_ID=test
      - AWS_SECRET_ACCESS_KEY=test
      - AWS_DYNAMODB_ENDPOINT=http://localstack:4566
      - AWS_SNS_ENDPOINT=http://localstack:4566
      - AWS_SQS_ENDPOINT=http://localstack:4566
      - ANALYTICS_EVENTS_TABLE=analytics-events
      - ANALYTICS_METRICS_TABLE=analytics-metrics
      - ANALYTICS_AGGREGATIONS_TABLE=analytics-aggregations
      - ANALYTICS_TOPIC_ARN=arn:aws:sns:eu-central-1:000000000000:analytics-events
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - LOG_LEVEL=INFO
    depends_on:
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy
      analytics-service:
        condition: service_healthy
    networks:
      - microservices-network
    dns:
      - 10.0.2.20
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import redis; r=redis.Redis(host='redis', port=6379, db=0); r.ping()"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Analytics Celery Worker for Maintenance Tasks
  analytics-worker-maintenance:
    build:
      context: ./app/services/analytics_service
      dockerfile: Dockerfile
    container_name: analytics-worker-maintenance
    command: ["python", "celery_worker.py", "--concurrency", "2", "--queues", "maintenance", "--log-level", "INFO"]
    environment:
      - FLASK_ENV=production
      - AWS_REGION=eu-central-1
      - AWS_ACCESS_KEY_ID=test
      - AWS_SECRET_ACCESS_KEY=test
      - AWS_DYNAMODB_ENDPOINT=http://localstack:4566
      - AWS_SNS_ENDPOINT=http://localstack:4566
      - AWS_SQS_ENDPOINT=http://localstack:4566
      - ANALYTICS_EVENTS_TABLE=analytics-events
      - ANALYTICS_METRICS_TABLE=analytics-metrics
      - ANALYTICS_AGGREGATIONS_TABLE=analytics-aggregations
      - ANALYTICS_TOPIC_ARN=arn:aws:sns:eu-central-1:000000000000:analytics-events
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - LOG_LEVEL=INFO
    depends_on:
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy
      analytics-service:
        condition: service_healthy
    networks:
      - microservices-network
    dns:
      - 10.0.2.20
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import redis; r=redis.Redis(host='redis', port=6379, db=0); r.ping()"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Analytics Celery Beat Scheduler
  analytics-beat:
    build:
      context: ./app/services/analytics_service
      dockerfile: Dockerfile
    container_name: analytics-beat
    command: ["python", "celery_worker.py", "--beat", "--log-level", "INFO"]
    environment:
      - FLASK_ENV=production
      - AWS_REGION=eu-central-1
      - AWS_ACCESS_KEY_ID=test
      - AWS_SECRET_ACCESS_KEY=test
      - AWS_DYNAMODB_ENDPOINT=http://localstack:4566
      - AWS_SNS_ENDPOINT=http://localstack:4566
      - AWS_SQS_ENDPOINT=http://localstack:4566
      - ANALYTICS_EVENTS_TABLE=analytics-events
      - ANALYTICS_METRICS_TABLE=analytics-metrics
      - ANALYTICS_AGGREGATIONS_TABLE=analytics-aggregations
      - ANALYTICS_TOPIC_ARN=arn:aws:sns:eu-central-1:000000000000:analytics-events
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - LOG_LEVEL=INFO
    depends_on:
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy
      analytics-service:
        condition: service_healthy
    networks:
      - microservices-network
    dns:
      - 10.0.2.20
    restart: unless-stopped
    volumes:
      - celerybeat-data:/tmp
    healthcheck:
      test: ["CMD", "python", "-c", "import redis; r=redis.Redis(host='redis', port=6379, db=0); r.ping()"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis for Caching
  redis:
    image: redis:7-alpine
    container_name: redis-cache
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    networks:
      - microservices-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 5s
      retries: 3

  # NGINX Load Balancer / API Gateway
  nginx:
    image: nginx:alpine
    container_name: api-gateway
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./infrastructure/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./infrastructure/nginx/conf.d:/etc/nginx/conf.d:ro
    depends_on:
      - product-service
      - user-service
      - checkout-service
    networks:
      - microservices-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 5s
      retries: 3

  # Grafana for Monitoring
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin123}
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource,grafana-polystat-panel,redis-datasource
      - GF_FEATURE_TOGGLES_ENABLE=traceqlEditor
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Viewer
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
      - GF_SECURITY_ALLOW_EMBEDDING=true
    volumes:
      - grafana-data:/var/lib/grafana
      - ./infrastructure/grafana/dashboards:/var/lib/grafana/dashboards:ro
      - ./infrastructure/grafana/provisioning:/etc/grafana/provisioning:ro
    networks:
      - microservices-network
    depends_on:
      - prometheus
      - jaeger
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Prometheus for Metrics Collection
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./infrastructure/prometheus/alert_rules.yml:/etc/prometheus/alert_rules.yml:ro
      - ./infrastructure/prometheus/recording_rules.yml:/etc/prometheus/recording_rules.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
      - '--web.enable-remote-write-receiver'
      - '--storage.tsdb.min-block-duration=5m'
      - '--storage.tsdb.max-block-duration=2h'
    networks:
      - microservices-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Jaeger for Distributed Tracing
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: jaeger
    ports:
      - "16686:16686"   # Jaeger UI
      - "14268:14268"   # Jaeger collector HTTP
      - "14250:14250"   # Jaeger collector gRPC
      - "14269:14269"   # Jaeger admin port
      - "9411:9411"     # Zipkin collector
      - "4317:4317"     # OTLP gRPC receiver
      - "4318:4318"     # OTLP HTTP receiver
    environment:
      - COLLECTOR_ZIPKIN_HOST_PORT=:9411
      - COLLECTOR_OTLP_ENABLED=true
      - METRICS_STORAGE_TYPE=prometheus
      - PROMETHEUS_SERVER_URL=http://prometheus:9090
      - QUERY_BASE_PATH=/jaeger
      - JAEGER_DISABLED=false
      - SPAN_STORAGE_TYPE=memory
    command: [
      "--memory.max-traces=10000",
      "--query.max-clock-skew-adjustment=1s",
      "--query.ui-config=/etc/jaeger/ui-config.json",
      "--collector.otlp.grpc.host-port=0.0.0.0:4317",
      "--collector.otlp.http.host-port=0.0.0.0:4318",
      "--prometheus.server-url=http://prometheus:9090"
    ]
    volumes:
      - ./infrastructure/jaeger/ui-config.json:/etc/jaeger/ui-config.json:ro
    networks:
      - microservices-network
    depends_on:
      - prometheus
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:14269/"]
      interval: 30s
      timeout: 10s
      retries: 3

  # k6 Load Testing Service
  k6:
    image: grafana/k6:latest
    container_name: k6-load-tester
    environment:
      - K6_PROMETHEUS_RW_SERVER_URL=http://prometheus:9090/api/v1/write
      - K6_PROMETHEUS_RW_TREND_STATS=p(95),p(99),min,max,avg,med
      - K6_PROMETHEUS_RW_PUSH_INTERVAL=5s
    volumes:
      - ./infrastructure/k6-scripts:/scripts:ro
    networks:
      - microservices-network
    # Will be controlled via API calls, not auto-start
    entrypoint: ["/bin/sh", "-c", "while true; do sleep 30; done"]
    depends_on:
      - prometheus
      - product-service
      - user-service
      - checkout-service
      - analytics-service
    restart: unless-stopped

  # Artillery Load Testing Service for User Journey Tests
  artillery:
    image: artilleryio/artillery:latest
    container_name: artillery-user-journey
    environment:
      - ARTILLERY_PROMETHEUS_GATEWAY=http://prometheus:9090/api/v1/write
      - ARTILLERY_STATSD_HOST=prometheus
      - ARTILLERY_STATSD_PORT=9125
      - NODE_ENV=production
    volumes:
      - ./infrastructure/artillery-scripts:/scripts:ro
    networks:
      - microservices-network
    # Will be controlled via API calls, not auto-start
    entrypoint: ["/bin/sh", "-c", "while true; do sleep 30; done"]
    depends_on:
      - prometheus
      - product-service
      - user-service
      - checkout-service
      - analytics-service
    restart: unless-stopped

networks:
  microservices-network:
    driver: bridge
    ipam:
      config:
        - subnet: 10.0.2.0/24

volumes:
  localstack-data:
  redis-data:
  grafana-data:
  prometheus-data:
  celerybeat-data: 